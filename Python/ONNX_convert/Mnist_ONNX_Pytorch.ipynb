{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ONNX Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67HnAXM_reco"
      },
      "source": [
        "[Пример с MNIST](https://colab.research.google.com/github/rpi-techfundamentals/fall2018-materials/blob/master/10-deep-learning/04-pytorch-mnist.ipynb#scrollTo=LOLocpDXq3nx)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_P8jiovqmgd",
        "outputId": "06c85c83-fb6b-4fe0-b70a-5b461d650830"
      },
      "source": [
        "!pip install onnxruntime==1.9.0\n",
        "!pip install torch torchvision\n",
        "!pip install onnx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnxruntime==1.9.0 in /usr/local/lib/python3.7/dist-packages (1.9.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.9.0) (3.17.3)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.9.0) (1.12)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.9.0) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->onnxruntime==1.9.0) (1.15.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.10.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.7/dist-packages (1.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.7.4.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.19.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx) (3.17.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkDNtVhbrA-3"
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import torch.onnx\n",
        "import onnxruntime\n",
        "from sklearn.metrics import classification_report as Report\n",
        "from onnxruntime.quantization import quantize_dynamic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyGMKCDLr57T"
      },
      "source": [
        "## MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPbFslUwr3ac"
      },
      "source": [
        "args={}\n",
        "kwargs={}\n",
        "args['batch_size']=1000\n",
        "args['test_batch_size']=1000\n",
        "args['epochs']=3  #The number of Epochs is the number of times you go through the full dataset. \n",
        "args['lr']=0.01 #Learning rate is how fast it will decend. \n",
        "args['momentum']=0.5 #SGD momentum (default: 0.5) Momentum is a moving average of our gradients (helps to keep direction).\n",
        "\n",
        "args['seed']=1 #random seed\n",
        "args['log_interval']=10\n",
        "args['cuda']=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMBI9jB3sBWD",
        "outputId": "06bf8a39-f6f7-4921-93df-e238cace2cb8"
      },
      "source": [
        "#load the data\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=args['batch_size'], shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=args['test_batch_size'], shuffle=True, **kwargs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTY3GNG0sHNg"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    #This defines the structure of the NN.\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()  #Dropout\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #Convolutional Layer/Pooling Layer/Activation\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2)) \n",
        "        #Convolutional Layer/Dropout/Pooling Layer/Activation\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        #Fully Connected Layer/Activation\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        #Fully Connected Layer/Activation\n",
        "        x = self.fc2(x)\n",
        "        #Softmax gets probabilities. \n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyBc-TxOsM1t"
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        if args['cuda']:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        #Variables in Pytorch are differenciable. \n",
        "        data, target = Variable(data), Variable(target)\n",
        "        #This will zero out the gradients for this batch. \n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        # Calculate the loss The negative log likelihood loss. It is useful to train a classification problem with C classes.\n",
        "        loss = F.nll_loss(output, target)\n",
        "        #dloss/dx for every Variable \n",
        "        loss.backward()\n",
        "        #to do a one-step update on our parameter.\n",
        "        optimizer.step()\n",
        "        #Print out the loss periodically. \n",
        "        if batch_idx % args['log_interval'] == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), \n",
        "                                                                           len(train_loader.dataset), \n",
        "                                                                           100. * batch_idx / len(train_loader), loss.data))\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        if args['cuda']:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "        output = model(data)\n",
        "        test_loss += F.nll_loss(output, target, size_average=False).data # sum up batch loss\n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),  \n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkFrGuBrsRJd",
        "outputId": "76e1c2e1-e6aa-4c81-cb81-f54e6f1835d3"
      },
      "source": [
        "model = Net()\n",
        "if args['cuda']:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=args['lr'], momentum=args['momentum'])\n",
        "\n",
        "for epoch in range(1, args['epochs'] + 1):\n",
        "    train(epoch)\n",
        "    test()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.334774\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 2.312112\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 2.298412\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 2.284640\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 2.286018\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 2.272294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 2.2452, Accuracy: 3607/10000 (36%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.252806\n",
            "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 2.248607\n",
            "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 2.224671\n",
            "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 2.204084\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 2.164259\n",
            "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 2.124230\n",
            "\n",
            "Test set: Average loss: 1.9436, Accuracy: 6257/10000 (63%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.047359\n",
            "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 1.938156\n",
            "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 1.841257\n",
            "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 1.711682\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 1.621157\n",
            "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 1.537818\n",
            "\n",
            "Test set: Average loss: 1.0572, Accuracy: 7959/10000 (80%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovDwFQp4uvp-"
      },
      "source": [
        "# Конвертирование в ONNX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzVhdgR6vOxW"
      },
      "source": [
        "Экспорт с помощью трассировки(для информации о запускаемых операциях), для запуска трассировки нужен вход"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYrmcNFdut3I"
      },
      "source": [
        "bs = 5\n",
        "inp = torch.randn(bs, 1, 28, 28, requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rFd6W5wxKvm",
        "outputId": "77765b62-f8ca-4e18-ea85-6132780826ec"
      },
      "source": [
        "inp.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "do_WyBuv7LR_",
        "outputId": "ea57d385-2db9-4eff-a062-93046dba8508"
      },
      "source": [
        "model(inp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.4647, -2.4803, -1.8364, -2.1460, -2.4728, -2.3880, -1.8757, -2.9909,\n",
              "         -2.3285, -2.5535],\n",
              "        [-1.9438, -2.9372, -2.2128, -2.3945, -2.3803, -2.2351, -2.0445, -2.5336,\n",
              "         -2.2964, -2.3615],\n",
              "        [-2.2160, -2.2806, -2.0913, -1.8523, -3.2853, -2.1227, -2.9352, -2.3848,\n",
              "         -2.0278, -2.5989],\n",
              "        [-2.0939, -2.4482, -1.8822, -1.9850, -2.8791, -2.3515, -2.4885, -2.5497,\n",
              "         -2.1527, -2.6315],\n",
              "        [-1.9028, -3.0507, -2.1980, -2.5940, -2.1863, -2.2174, -2.0641, -2.5649,\n",
              "         -2.3679, -2.3123]], grad_fn=<LogSoftmaxBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9TOfMS2xRxt"
      },
      "source": [
        "torch.onnx.export(model, inp, 'mnist_torch.onnx', input_names=['input_28_28'], output_names=['output_log_softmax'],\n",
        "                   dynamic_axes={'input_28_28' : {0 : 'batch_size'},    #  Динамические оси, для переменного размера\n",
        "                                 'output_log_softmax' : {0 : 'batch_size'}},\n",
        "                  opset_version=10 # Версия с поддержкой квантования, до 9 не поддерживается\n",
        "                  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6AwQofbyrA5"
      },
      "source": [
        "## Тестирование"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_e0laIWyvYc"
      },
      "source": [
        "sess = onnxruntime.InferenceSession('mnist_torch.onnx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYxlFSaYy3aG",
        "outputId": "614e3f77-1fd1-428c-cdaf-8429cae62991"
      },
      "source": [
        "inputs = sess.get_inputs()\n",
        "for inp in inputs:\n",
        "  print(inp.name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_28_28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTn6kAOty7cW"
      },
      "source": [
        "def OnnxTest(x_test, y_test, sess):\n",
        "  input_name = sess.get_inputs()[0].name\n",
        "  output_name = sess.get_outputs()[0].name\n",
        "  outp = sess.run([output_name], {input_name: x_test})\n",
        "\n",
        "  class_pred = []\n",
        "  for prob in outp[0]:\n",
        "    class_pred.append(np.argmax(prob))\n",
        "\n",
        "  class_real = []\n",
        "  for real in y_test:\n",
        "    class_real.append(real)\n",
        "\n",
        "  print(Report(class_real, class_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUTjO49PzLI5",
        "outputId": "14d23216-f91e-45e6-9ec2-ec6b501b3b3a"
      },
      "source": [
        "data = test_loader.dataset\n",
        "x_test = data.train_data.reshape(data.train_data.shape[0], 1, 28,28).numpy().astype(np.float32)\n",
        "\n",
        "y_test = data.train_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:62: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:52: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH3B30-Tz6Ff",
        "outputId": "2c34d519-f94c-4b53-e736-7103ee6c3ae6"
      },
      "source": [
        "OnnxTest(x_test, y_test, sess)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.97      0.91       980\n",
            "           1       0.93      0.96      0.95      1135\n",
            "           2       0.80      0.87      0.84      1032\n",
            "           3       0.72      0.83      0.77      1010\n",
            "           4       0.77      0.81      0.79       982\n",
            "           5       0.85      0.49      0.62       892\n",
            "           6       0.79      0.90      0.84       958\n",
            "           7       0.76      0.87      0.81      1028\n",
            "           8       0.77      0.64      0.70       974\n",
            "           9       0.82      0.64      0.72      1009\n",
            "\n",
            "    accuracy                           0.80     10000\n",
            "   macro avg       0.81      0.80      0.79     10000\n",
            "weighted avg       0.81      0.80      0.80     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej37vpat78YX"
      },
      "source": [
        "## Квантование"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRtX4b517-KH",
        "outputId": "bdcb5643-2aca-4f2e-d046-30c3946e99fa"
      },
      "source": [
        "quantize_dynamic('/content/mnist_torch.onnx', '/content/mnist_torch_q.onnx')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:The original model opset version is 10, which does not support node fusions. Please update the model to opset >= 11 for better performance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxx961xR9uHw"
      },
      "source": [
        "sess_q = onnxruntime.InferenceSession('mnist_torch_q.onnx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsRZDJco926P",
        "outputId": "89e7c6e0-0360-41fc-919f-6cc226ea2339"
      },
      "source": [
        "OnnxTest(x_test, y_test, sess_q)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.97      0.91       980\n",
            "           1       0.93      0.96      0.95      1135\n",
            "           2       0.80      0.87      0.83      1032\n",
            "           3       0.73      0.83      0.78      1010\n",
            "           4       0.77      0.80      0.79       982\n",
            "           5       0.84      0.49      0.62       892\n",
            "           6       0.78      0.90      0.84       958\n",
            "           7       0.76      0.87      0.81      1028\n",
            "           8       0.77      0.64      0.70       974\n",
            "           9       0.82      0.65      0.72      1009\n",
            "\n",
            "    accuracy                           0.80     10000\n",
            "   macro avg       0.81      0.80      0.79     10000\n",
            "weighted avg       0.81      0.80      0.80     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18thn1WuKEUM",
        "outputId": "98773002-e264-4697-8c3f-27c232ab01b1"
      },
      "source": [
        "%ls -l --block-size=KB"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 127kB\n",
            "-rw-r--r-- 1 root root 89kB Oct  4 11:51 mnist_torch.onnx\n",
            "-rw-r--r-- 1 root root 30kB Oct  4 11:52 mnist_torch_q.onnx\n",
            "drwxr-xr-x 1 root root  5kB Sep 30 17:12 \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    }
  ]
}